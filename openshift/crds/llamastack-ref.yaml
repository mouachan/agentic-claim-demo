apiVersion: llamastack.opendatahub.io/v1
kind: LlamaStackReference
metadata:
  name: claims-llamastack
  namespace: claims-demo
  labels:
    app: claims-processing
    component: llm-service
spec:
  # Reference to the existing LlamaStack instance in RHOAI 3.0
  llamaStackName: default-llamastack
  namespace: openshift-ai

  # Endpoints to enable
  endpoints:
    inference: true       # Text generation
    embeddings: true      # Vector embeddings for RAG
    agents: true          # Agent runtime capabilities
    safety: true          # Safety & guardrails integration

  # Configuration for inference
  inference:
    modelName: llama-3.1-8b-instruct  # Default model to use
    temperature: 0.7
    maxTokens: 2048
    topP: 0.9

  # Configuration for embeddings
  embeddings:
    modelName: sentence-transformers/all-mpnet-base-v2
    dimension: 768  # Embedding dimension

  # Service account for authentication
  serviceAccount:
    name: claims-demo-sa
    create: true

  # Resource requests/limits for client connections
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
