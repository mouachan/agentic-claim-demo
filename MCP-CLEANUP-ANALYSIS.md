# Analyse et Nettoyage des MCP Servers

Date: 2025-12-24
Objectif: Nettoyer l'architecture pour Ãªtre conforme Ã  LlamaStack

## ProblÃ¨me IdentifiÃ©

L'architecture actuelle utilise des **services HTTP custom** au lieu de **vrais serveurs MCP** avec le protocole standard (SSE). De plus, l'orchestrateur custom n'est pas nÃ©cessaire car **LlamaStack Agents API gÃ¨re l'orchestration**.

## Architecture Actuelle (Incorrecte) âŒ

```
Frontend â†’ Backend â†’ Orchestrator Server (custom HTTP)
                           â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â†“          â†“          â†“
             OCR       RAG      Guardrails
          (HTTP)     (HTTP)      (vide)
```

**ProblÃ¨mes:**
1. **Orchestrator Server** = orchestration manuelle custom
   - Avec LlamaStack Agents API, c'est LlamaStack qui orchestre
   - Redondant et inutile

2. **Serveurs MCP = HTTP custom** (FastAPI), pas MCP protocol (SSE)
   - Ne peuvent pas Ãªtre enregistrÃ©s comme MCP servers dans LlamaStack
   - Pas de dÃ©couverte automatique des tools

3. **Guardrails Server** = rÃ©pertoire vide
   - On utilise TrustyAI Guardrails Orchestrator

4. **Logique d'orchestration dupliquÃ©e**
   - `llamastack_agent_orchestrator.py` = orchestration avec tool calling
   - Mais LlamaStack Agents API fait dÃ©jÃ  Ã§a automatiquement

## Architecture Cible (Correcte) âœ…

```
Frontend â†’ Backend â†’ LlamaStack Distribution
                         â†“ (Agents API)
                         â†“ (Tool Runtime: MCP Protocol SSE)
                    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
                    â†“    â†“    â†“
                  OCR  RAG  TrustyAI
                 (MCP) (MCP) (Guardrails)
                  SSE   SSE
```

**Ce qui change:**
1. **LlamaStack Agents API** gÃ¨re l'orchestration (pas d'orchestrator custom)
2. **Vrais serveurs MCP** avec protocole SSE
3. **TrustyAI Guardrails Orchestrator** pour la sÃ©curitÃ© (via CRD)

## Inventaire des MCP Servers Actuels

### 1. `orchestrator_server/` âŒ **Ã€ SUPPRIMER**

**Fichiers:**
```
orchestrator_server/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ llamastack_agent_orchestrator.py    # Orchestration avec LLM
â”œâ”€â”€ llamastack_orchestrator.py
â”œâ”€â”€ llamastack_responses_orchestrator.py
â”œâ”€â”€ prompts.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ server.py                           # FastAPI server
```

**Raison de suppression:**
- **LlamaStack Agents API gÃ¨re dÃ©jÃ  l'orchestration**
- L'agent LlamaStack appelle automatiquement les tools MCP dans le bon ordre
- Le fichier `llamastack_agent_orchestrator.py` implÃ©mente du tool calling, mais c'est dÃ©jÃ  fait par LlamaStack
- Redondant et crÃ©e de la complexitÃ© inutile

**Workflow avec LlamaStack (sans orchestrator custom):**
```python
# Backend appelle directement LlamaStack Agents API
response = await llamastack_client.post("/v1beta/agents/turn/create", json={
    "agent_config": {
        "model": "llama-instruct-32-3b",
        "tools": ["mcp::ocr-server::ocr_document",
                  "mcp::rag-server::retrieve_user_info",
                  "mcp::rag-server::retrieve_similar_claims"],
        "instructions": "Process this claim..."
    },
    "messages": [{"role": "user", "content": "Process claim 12345"}]
})

# LlamaStack orchestre automatiquement:
# 1. Appelle ocr_document
# 2. Appelle retrieve_user_info
# 3. Appelle retrieve_similar_claims
# 4. GÃ©nÃ¨re la dÃ©cision finale
# Tout cela sans orchestrator custom!
```

### 2. `guardrails_server/` âŒ **Ã€ SUPPRIMER**

**Fichiers:**
```
guardrails_server/
(vide - 0 fichiers)
```

**Raison de suppression:**
- RÃ©pertoire vide
- On utilise **TrustyAI Guardrails Orchestrator** (CRD OpenShift AI)
- Voir `TRUSTYAI-GUARDRAILS-GUIDE.md` pour la configuration

### 3. `ocr_server/` âœ… **Ã€ CONSERVER mais CONVERTIR au protocole MCP**

**Fichiers:**
```
ocr_server/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ prompts.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ server.py                # FastAPI HTTP - Ã  convertir en MCP SSE
```

**Ã‰tat actuel:**
- Service HTTP FastAPI avec endpoint `POST /ocr_document`
- Pas de protocole MCP (SSE)

**Ã€ faire:**
- Convertir en vrai serveur MCP avec protocole SSE
- Exposer le tool `ocr_document` via MCP
- Garder la logique OCR (Tesseract + validation LLM)

**Tool MCP Ã  exposer:**
```python
{
    "type": "function",
    "function": {
        "name": "ocr_document",
        "description": "Extract text from document images or PDFs using OCR and validate with LLM",
        "parameters": {
            "type": "object",
            "properties": {
                "document_path": {"type": "string"},
                "document_type": {"type": "string", "default": "claim_form"},
                "language": {"type": "string", "default": "eng"}
            },
            "required": ["document_path"]
        }
    }
}
```

### 4. `rag_server/` âœ… **Ã€ CONSERVER mais CONVERTIR au protocole MCP**

**Fichiers:**
```
rag_server/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ prompts.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ server.py                # FastAPI HTTP - Ã  convertir en MCP SSE
```

**Ã‰tat actuel:**
- Service HTTP FastAPI avec 3 endpoints
- Pas de protocole MCP (SSE)

**Ã€ faire:**
- Convertir en vrai serveur MCP avec protocole SSE
- Exposer 3 tools via MCP
- Garder la logique RAG (pgvector + embeddings)

**Tools MCP Ã  exposer:**
```python
[
    {
        "type": "function",
        "function": {
            "name": "retrieve_user_info",
            "description": "Retrieve user information and contracts using vector search",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {"type": "string"},
                    "query": {"type": "string"},
                    "top_k": {"type": "integer", "default": 5}
                },
                "required": ["user_id", "query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "retrieve_similar_claims",
            "description": "Find similar historical claims using vector similarity",
            "parameters": {
                "type": "object",
                "properties": {
                    "claim_text": {"type": "string"},
                    "top_k": {"type": "integer", "default": 10},
                    "min_similarity": {"type": "number", "default": 0.7}
                },
                "required": ["claim_text"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_knowledge_base",
            "description": "Search the knowledge base for policy information",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string"},
                    "top_k": {"type": "integer", "default": 5}
                },
                "required": ["query"]
            }
        }
    }
]
```

## Protocole MCP (SSE) - Template

Voici comment un vrai serveur MCP doit Ãªtre structurÃ©:

```python
from fastapi import FastAPI
from sse_starlette.sse import EventSourceResponse
import asyncio
import json

app = FastAPI()

# DÃ©finition des tools MCP
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "ocr_document",
            "description": "Extract text from documents",
            "parameters": {
                "type": "object",
                "properties": {
                    "document_path": {"type": "string"}
                },
                "required": ["document_path"]
            }
        }
    }
]

# SSE endpoint pour la dÃ©couverte des tools
@app.get("/mcp/sse")
async def mcp_sse_endpoint():
    """
    Server-Sent Events endpoint pour MCP protocol.
    LlamaStack se connecte ici pour dÃ©couvrir les tools.
    """
    async def event_generator():
        # Envoyer la liste des tools disponibles
        yield {
            "event": "tools",
            "data": json.dumps({"tools": TOOLS})
        }

        # Keep-alive
        while True:
            await asyncio.sleep(30)
            yield {
                "event": "ping",
                "data": json.dumps({"status": "alive"})
            }

    return EventSourceResponse(event_generator())

# Endpoint pour exÃ©cuter un tool
@app.post("/mcp/tools/{tool_name}")
async def execute_tool(tool_name: str, params: dict):
    """
    Endpoint appelÃ© par LlamaStack pour exÃ©cuter un tool.
    """
    if tool_name == "ocr_document":
        result = await process_ocr(params["document_path"])
        return {"success": True, "result": result}

    return {"success": False, "error": "Unknown tool"}
```

## Plan de Nettoyage et Conversion

### Phase 1: Suppression âŒ

#### 1.1 Supprimer `orchestrator_server/`

```bash
# Supprimer le rÃ©pertoire complet
rm -rf backend/mcp_servers/orchestrator_server/

# Supprimer les dÃ©ploiements OpenShift associÃ©s
oc delete deployment orchestrator-server -n claims-demo
oc delete service orchestrator-server -n claims-demo
oc delete configmap orchestrator-server-config -n claims-demo
```

**Impact:**
- Backend n'appelle plus l'orchestrator
- Backend appelle directement LlamaStack Agents API
- LlamaStack orchestre les tools MCP

**Fichiers backend Ã  modifier:**
- `backend/app/api/claims.py` - supprimer les appels Ã  l'orchestrator
- `backend/app/services/claim_processor.py` - utiliser LlamaStack Agents API

#### 1.2 Supprimer `guardrails_server/`

```bash
# Supprimer le rÃ©pertoire vide
rm -rf backend/mcp_servers/guardrails_server/
```

**Remplacement:**
- TrustyAI Guardrails Orchestrator (voir `TRUSTYAI-GUARDRAILS-GUIDE.md`)

### Phase 2: Conversion au Protocole MCP âœ…

#### 2.1 Convertir `ocr_server/` en vrai MCP server

**Nouveau fichier:** `backend/mcp_servers/ocr_server/mcp_server.py`

Changements:
- Ajouter endpoint SSE `/mcp/sse` pour la dÃ©couverte des tools
- Changer endpoint REST de `/ocr_document` Ã  `/mcp/tools/ocr_document`
- ImplÃ©menter le protocole MCP standard
- Exposer les tools au format MCP

**DÃ©pendances Ã  ajouter:**
```
sse-starlette==1.6.5
```

#### 2.2 Convertir `rag_server/` en vrai MCP server

**Nouveau fichier:** `backend/mcp_servers/rag_server/mcp_server.py`

Changements:
- Ajouter endpoint SSE `/mcp/sse` pour la dÃ©couverte des tools
- Changer endpoints REST:
  - `/retrieve_user_info` â†’ `/mcp/tools/retrieve_user_info`
  - `/retrieve_similar_claims` â†’ `/mcp/tools/retrieve_similar_claims`
  - `/search_knowledge_base` â†’ `/mcp/tools/search_knowledge_base`
- ImplÃ©menter le protocole MCP standard
- Exposer les 3 tools au format MCP

**DÃ©pendances Ã  ajouter:**
```
sse-starlette==1.6.5
```

### Phase 3: Configuration LlamaStack ğŸ”§

#### 3.1 Enregistrer les MCP servers dans LlamaStack

**Fichier:** `openshift/llamastack/run.yaml`

```yaml
providers:
  tool_runtime:
    - provider_id: model-context-protocol
      provider_type: remote::model-context-protocol
      config:
        mcp_servers:
          # OCR MCP Server
          - name: ocr-server
            uri: sse://ocr-mcp-server.claims-demo.svc.cluster.local:8080/mcp/sse
            tools:
              - ocr_document

          # RAG MCP Server
          - name: rag-server
            uri: sse://rag-mcp-server.claims-demo.svc.cluster.local:8080/mcp/sse
            tools:
              - retrieve_user_info
              - retrieve_similar_claims
              - search_knowledge_base

# Tool groups pour les agents
tool_groups:
  - toolgroup_id: builtin::rag
    provider_id: rag-runtime

  - toolgroup_id: claims-processing
    provider_id: model-context-protocol
    tools:
      - name: ocr-server::ocr_document
      - name: rag-server::retrieve_user_info
      - name: rag-server::retrieve_similar_claims
      - name: rag-server::search_knowledge_base
```

#### 3.2 Modifier le Backend pour utiliser Agents API

**Fichier:** `backend/app/services/claim_processor.py`

Avant (avec orchestrator custom):
```python
# Appeler l'orchestrator custom
response = await httpx.post(
    f"{ORCHESTRATOR_URL}/orchestrate_claim_processing",
    json={"claim_id": claim_id, "document_path": doc_path}
)
```

AprÃ¨s (avec LlamaStack Agents API):
```python
# CrÃ©er une session d'agent
session_id = await llamastack.create_agent_session(
    agent_config={
        "model": "llama-instruct-32-3b",
        "tools": ["claims-processing"],  # Tool group
        "instructions": "Process this claim by: 1) OCR the document, 2) Retrieve user info, 3) Find similar claims, 4) Make a decision",
        "enable_session_persistence": True
    },
    session_name=f"claim-{claim_id}"
)

# Lancer le traitement (LlamaStack orchestre automatiquement)
result = await llamastack.run_agent_turn(
    session_id=session_id,
    messages=[{
        "role": "user",
        "content": f"Process claim {claim_id} with document at {doc_path}"
    }]
)
```

## BÃ©nÃ©fices du Nettoyage

### SimplicitÃ© âœ¨
- **Moins de code custom** Ã  maintenir
- **Architecture standard** LlamaStack
- **Protocole MCP officiel** au lieu de HTTP custom

### Performance ğŸš€
- **DÃ©couverte automatique** des tools via SSE
- **Orchestration optimisÃ©e** par LlamaStack
- **Pas de hop supplÃ©mentaire** (orchestrator)

### ConformitÃ© ğŸ“‹
- **Architecture Red Hat officielle**
- **Protocole MCP standard** (opendatahub-io/llama-stack-demos)
- **SupportÃ© et documentÃ©** par Red Hat

### Ã‰volutivitÃ© ğŸ“ˆ
- **Facile d'ajouter de nouveaux tools** MCP
- **LlamaStack gÃ¨re la complexitÃ©** de l'orchestration
- **Tool calling automatique** avec le bon ordre

## Structure Finale des MCP Servers

```
backend/mcp_servers/
â”œâ”€â”€ ocr_server/              âœ… MCP Server (SSE)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ mcp_server.py        â† Nouveau: Protocole MCP
â”‚   â”œâ”€â”€ ocr_logic.py         â† Logique OCR (Tesseract)
â”‚   â”œâ”€â”€ prompts.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ rag_server/              âœ… MCP Server (SSE)
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ mcp_server.py        â† Nouveau: Protocole MCP
    â”œâ”€â”€ rag_logic.py         â† Logique RAG (pgvector)
    â”œâ”€â”€ prompts.py
    â””â”€â”€ requirements.txt

SupprimÃ©s:
âŒ orchestrator_server/      (LlamaStack Agents API gÃ¨re l'orchestration)
âŒ guardrails_server/        (TrustyAI Guardrails Orchestrator)
```

## Ordre d'ExÃ©cution

1. âœ… **Documenter l'analyse** (ce fichier)
2. âŒ **Supprimer `orchestrator_server/`** et `guardrails_server/`
3. ğŸ”„ **Convertir `ocr_server/`** au protocole MCP (SSE)
4. ğŸ”„ **Convertir `rag_server/`** au protocole MCP (SSE)
5. ğŸ”§ **Configurer LlamaStack** pour enregistrer les MCP servers
6. ğŸ”§ **Modifier le backend** pour utiliser Agents API au lieu de l'orchestrator
7. ğŸ§ª **Tester** le workflow complet end-to-end
8. ğŸ“ **Mettre Ã  jour** la documentation

## Validation

AprÃ¨s le nettoyage, vÃ©rifier:

- [ ] `orchestrator_server/` supprimÃ©
- [ ] `guardrails_server/` supprimÃ©
- [ ] `ocr_server/` expose endpoint SSE `/mcp/sse`
- [ ] `rag_server/` expose endpoint SSE `/mcp/sse`
- [ ] LlamaStack dÃ©couvre automatiquement les tools MCP
- [ ] Backend appelle LlamaStack Agents API (pas d'orchestrator)
- [ ] TrustyAI Guardrails Orchestrator configurÃ©
- [ ] Workflow end-to-end fonctionne

## Conclusion

Le nettoyage va:
1. **Supprimer** l'orchestrator custom (redondant avec LlamaStack)
2. **Supprimer** le guardrails vide (remplacÃ© par TrustyAI)
3. **Convertir** les serveurs HTTP custom en vrais serveurs MCP (SSE)
4. **Simplifier** l'architecture pour Ãªtre conforme Ã  Red Hat OpenShift AI 3.0

RÃ©sultat: Architecture propre, standard, et maintainable. âœ…
